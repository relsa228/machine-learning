{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №1. Основы машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tar_path = 'notMNIST_large.tar.gz'\n",
    "tar_general_dir = 'notMNIST_large'\n",
    "total_images = 200000 + 10000 + 19000\n",
    "train_size = 200000 // 10\n",
    "val_size = 10000 // 10\n",
    "test_size = 19000 // 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Загрузите данные и отобразите на экране несколько из изображений с помощью языка Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(tar_path, 'r') as tar:\n",
    "    image_files = tar.getmembers()\n",
    "    \n",
    "    for image_file in image_files[:3]:\n",
    "        extracted_file = tar.extractfile(image_file)\n",
    "        if extracted_file:\n",
    "            image = Image.open(io.BytesIO(extracted_file.read()))\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Проверьте, что классы являются сбалансированными, т.е. количество изображений, принадлежащих каждому из классов, примерно одинаково (В данной задаче 10 классов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения в архиве с выборкой помещены в 10 папок, каждая из которых соответствует своему классу, следовательно, задача сводится к подсчету изображений в каждой из папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_counts = defaultdict(int)\n",
    "general_size = 0\n",
    "\n",
    "with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile():\n",
    "            parts = member.name.split('/')\n",
    "            if len(parts) > 1 and parts[0] == tar_general_dir:\n",
    "                folder_name = parts[1]\n",
    "                if folder_name in 'ABCDEFGHIJ':\n",
    "                    folder_counts[folder_name] += 1\n",
    "                \n",
    "for folder in 'ABCDEFGHIJ':\n",
    "    print(f'Класс {folder}: {folder_counts[folder]} объектов')\n",
    "    general_size += folder_counts[folder]\n",
    "    \n",
    "print(f'Общее количество: {general_size} объектов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, классы действительно являются сбалансированными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3** Разделите данные на три подвыборки: обучающую (200 тыс. изображений), валидационную (10 тыс. изображений) и контрольную (тестовую) (19 тыс. изображений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим все изображения из архива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "    tar.extractall(path='.')\n",
    "\n",
    "image_paths = defaultdict(list)\n",
    "\n",
    "for folder in os.listdir(tar_general_dir):\n",
    "    folder_path = os.path.join(tar_general_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            image_paths[folder].append(os.path.join(folder_path, img_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим изображения на три выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list, test_list = [], [], []\n",
    "for class_images in image_paths.values():\n",
    "    random.shuffle(class_images)\n",
    "    train_list.extend(class_images[:train_size])\n",
    "    val_list.extend(class_images[train_size:train_size + val_size])\n",
    "    test_list.extend(class_images[train_size + val_size:train_size + val_size + test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** Проверьте, что данные из обучающей выборки не пересекаются с данными из валидационной и контрольной выборок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(train_list).isdisjoint(set(val_list + test_list)):\n",
    "    print(\"Списки не содержат одинаковых элементов.\")\n",
    "else:\n",
    "    print(\"Списки содержат одинаковые элементы.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.** Постройте простейший классификатор (например, с помощью логистической регрессии). Постройте график зависимости точности классификатора от размера обучающей выборки (50, 100, 1000, 50000).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию для загрузки данных и создадим маркированные списки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_list):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_path in image_list:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            #img = img.resize((64, 64))\n",
    "            img_array = np.array(img).flatten()  # Преобразование изображения в одномерный массив\n",
    "            data.append(img_array)\n",
    "            label = os.path.basename(os.path.dirname(img_path))  # Метка класса\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            print(\"Unprocessable entity\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "train_data, train_labels = load_images(train_list)\n",
    "val_data, val_labels = load_images(val_list)\n",
    "test_data, test_labels = load_images(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем обучение модели. Выставим желаемую точность модели на 82%. Для достижения желаемой точности проведем серию обучений с разным количеством итераций (начальное значение 1000). Количество итераций будет увеличиваться на 100, если после проверки обученной модели на валидационных данных требуемая точность не будет достигнута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 1000\n",
    "accuracy_desire = 0.82\n",
    "\n",
    "while True:\n",
    "    model = LogisticRegression(max_iter=max_iter)\n",
    "    model.fit(train_data, train_labels)\n",
    "    y_pred = model.predict(val_data)\n",
    "    accuracy = accuracy_score(val_labels, y_pred)\n",
    "    \n",
    "    print(f'Точность модели на валидационном наборе: {accuracy:.2f}\\nПри {max_iter} итерациях\\n')\n",
    "    \n",
    "    if accuracy >= accuracy_desire:\n",
    "        break\n",
    "    \n",
    "    max_iter += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка на валидационном наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(val_data)\n",
    "val_accuracy = accuracy_score(val_labels, y_val_pred)\n",
    "print(f'Точность модели на валидационном наборе: {val_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем оценку полученной модели. Оценка на тестовом наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data)\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f'Точность модели на тестовом наборе: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили удовлетворительную точность на тестовых и валидационных данных. Теперь проведем исследования зависимости точности классификатора от размеров выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим размеры обучающих выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [50, 100, 1000, 5000]\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели и получим их точности на разных размерностях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, train_size=size, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracies.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, accuracies, marker='o')\n",
    "plt.title('Зависимость точности классификатора от размера обучающей выборки')\n",
    "plt.xlabel('Размер обучающей выборки')\n",
    "plt.ylabel('Точность')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем дополнительные исследования. Изменим количество итераций, построим пять графиков на 50, 100, 200, 1000 и 2000 итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_50 = []\n",
    "accuracies_100 = []\n",
    "accuracies_200 = []\n",
    "accuracies_2000 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на 50 итерациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, train_size=size, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=50)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracies_50.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на 100 итерациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, train_size=size, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracies_100.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на 200 итерациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, train_size=size, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracies_200.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на 2000 итерациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in train_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, train_size=size, random_state=42)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=2000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracies_2000.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, accuracies_50, marker='o', label=\"50\")\n",
    "plt.plot(train_sizes, accuracies_100, marker='o', label=\"100\")\n",
    "plt.plot(train_sizes, accuracies_200, marker='o', label=\"200\")\n",
    "plt.plot(train_sizes, accuracies, marker='o', label=\"1000\")\n",
    "plt.plot(train_sizes, accuracies_2000, marker='o', label=\"2000\")\n",
    "plt.title('Зависимость точности классификатора от размера обучающей выборки')\n",
    "plt.xlabel('Размер обучающей выборки')\n",
    "plt.ylabel('Точность')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, отличия в точности заметны уже при выборке размером 1000 объектов, а при выборке размером 5000 эти отличия становятся довольно значительными. Связано это может быть с проблемой переобучения модели (значительное кол-во итераций при малом размере набора данных)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

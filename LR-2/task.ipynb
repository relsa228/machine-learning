{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №2. Реализация глубокой нейронной сет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "tar_path = 'notMNIST_large.tar.gz'\n",
    "tar_general_dir = 'notMNIST_large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.** Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим все изображения из архива"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "    tar.extractall(path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просеем выборку и удалим из нее все битые файлы. Они помешают работе генератора в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(tar_general_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()\n",
    "        except:\n",
    "            print(f\"File removed: {file_path}\")\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем модель с пятью слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))  # Преобразование 2D изображений в 1D вектор\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Выходной слой с softmax активацией для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем модель и получим информацию о ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим генераторы. Генератор тренировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "    validation_split=0.05)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    tar_general_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    subset=\"training\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генератор тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    tar_general_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель и получим ее точность на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, epochs=10)\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.** Как улучшилась точность классификатора по сравнению с логистической регрессией?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно пронаблюдать значительный рост точности классификации. Связано это с использованием нескольких слоев для построения полносвязной нейронной сети, вместо единственной классифицирующей модели (в прошлой лабораторной это была логистическая регрессия)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.** Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сутью метода `Dropout` является добавление слоя сброса после некоторого полносвязного слоя. Слой сброса с некоторой вероятностью должен отключать случаюные нейроны во время каждой итерации обучения, что помогает предотвратить переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Регуляризация` добавлена к последнему полносвязному слою. Она выставляет штраф за большие веса, что также помогает предотвратить переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем и обучим новую модель, а также проведем ее оценку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_generator, epochs=10)\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, точность осталась примерно на тех же значениях, что и была. Это означает, что переобучение на десяти эпохах для данного набора данных отсутсвует."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.** Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для внедрения динамической скорости обучения необходимо определить `Learning Rate Scheduler` и поменять оптимизатор на `adam`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию `callback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return float(lr)\n",
    "    else:\n",
    "        return float(lr * math.exp(-0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируем и обучим новую модель, а также проведем ее оценку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_generator, epochs=10, callbacks=[callback])\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внедрение динамической скорости обучения несколько повысило точность классификаци, однако уровня 97% достигнуть не удалось. Дальнейшее повышение точности модели, очевидно, возможно лишь через увеличение количества эпох обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
